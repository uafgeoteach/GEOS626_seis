{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy.linalg import inv\n",
    "import numpy.matlib\n",
    "from scipy.stats.distributions import chi2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.linalg as la\n",
    "import sys\n",
    "\n",
    "from plot_histo import plot_histo\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 8, 8\n",
    "plt.rcParams['lines.linewidth'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genlsq = Generalized Least Squares\n",
    "# Template script for the iterative quasi-Newton method for a 4-parameter\n",
    "# inversion for epicenter (xs, ys), origin time (ts), and velocity (V).\n",
    "# The algorithm employs generalized least squares, where by both data\n",
    "# covariances and model covariances are used.\n",
    "#\n",
    "# Background reading: Tarantola book (2005), Ch. 3 and Appendix 6.22\n",
    "#\n",
    "# calls forward_epicenter.ipynb, plot_histo()\n",
    "#\n",
    "# contributors: Carl Tape, Nealey Sims*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "nsamples = 1000;\n",
    "irandom_initial_model = 0;      # 0(fixed), 1(random)\n",
    "irandom_target_model = 0;       # 0(fixed), 1(random)\n",
    "idata_errors = 2;               # 0(none),  1(random), 2(fixed)\n",
    "ifig = 1;                       # 0,1\n",
    "\n",
    "inormalization = 1;\n",
    "stnsamples = str(nsamples) + ' samples'\n",
    "stlabS = ('Sd(m^k)','Sm(m^k)','S(m^k) = Sd + Sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORWARD PROBLEM: EXPLORE THIS SEPARATE NOTEBOOK   \n",
    "%run ./forward_epicenter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for prior and initial models (these are not used)\n",
    "dprior   = d(mprior)\n",
    "dinitial = d(minitial);\n",
    "\n",
    "if ifig==1:\n",
    "    # plot different histograms of properties of the prior model covariance samples\n",
    "    fig=plt.figure(figsize=(9,9))\n",
    "    for kk in range(nparm):\n",
    "        sigma = sigma_prior[kk]\n",
    "        #edges = [-4*sigma: sigma/2 : 4*sigma]\n",
    "        edges=np.arange(-4*sigma,4*sigma,sigma/2)\n",
    "        etemp = cov_samples_m[kk,:]\n",
    "        plt.subplot(2,2,kk+1)\n",
    "        plt.grid()\n",
    "        plot_histo(etemp,edges,2);\n",
    "        #plt.bar(etemp)\n",
    "        plt.ylim([0, 0.4])\n",
    "        plt.title('mprior samples: Model parameter '+str(kk+1)+' ('+str(mlabs[kk])+')\\n'+'mean = %.5f; std = %.5f' % (np.mean(etemp),np.std(etemp)))\n",
    "        plt.tight_layout()\n",
    "    # plot different histograms of properties of the data covariance samples\n",
    "    fig2 = plt.figure(figsize=(9,11))\n",
    "    for ii in range(ndata):\n",
    "        sigma = sigma_obs[ii];\n",
    "        edges=np.arange(-4*sigma,4*sigma,sigma/2)\n",
    "        etemp = cov_samples_d[ii,:]\n",
    "        plt.subplot(4,3,ii+1); \n",
    "        plot_histo(etemp,edges); \n",
    "        plt.ylim([0, 0.4]);\n",
    "        plt.title('Data index ' + str(ii+1) +'\\n'+'mean = %.5f; std = %.5f' % (np.mean(etemp),np.std(etemp))) \n",
    "        plt.tight_layout()\n",
    "    fig3 = plt.figure(figsize=(10,10))\n",
    "    plt.plot(dobs_samples,'.-');\n",
    "    p1 = plt.plot(dprior,'bo-',linewidth=2,markersize=10,markerfacecolor='b',markeredgecolor='w')\n",
    "    p2 = plt.plot(dinitial,'ko-',linewidth=2,markersize=10,markerfacecolor='k',markeredgecolor='w');\n",
    "    p3 = plt.plot(dtarget,'ro--',linewidth=2,markersize=10,markerfacecolor='r',markeredgecolor='w');\n",
    "    p4 = plt.plot(dobs,'ro-',linewidth=2,markersize=10,markerfacecolor='r',markeredgecolor='w');\n",
    "    plt.legend([p1[0], p2[0], p3[0], p4[0]],['g(mprior)','g(minitial)','g(mtarget)','g(mtarget) + errors',\n",
    "        'location','northwest'])\n",
    "    #title(' BLACK = d(mprior);  RED DASHED = d(mtarget);  RED = d(mtarget) + errors');\n",
    "    plt.xlim([0.5, ndata+0.5]); #set(gca,'xtick',[1:ndata]);\n",
    "    plt.xlabel('Data index'); plt.ylabel('Prediction value, g(m)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISFIT FUNCTION: least squares, Tarantola (2005), Eq. 6.251\n",
    "# This calls the function d(m) to compute the predictions.\n",
    "\n",
    "# data misfit\n",
    "def Sd(m,dobs,icobs):\n",
    "    sd=((np.dot(0.5,(d(m)-dobs).T))@icobs)@(d(m)-dobs)\n",
    "    return sd\n",
    "# model misfit (related to regularization)\n",
    "def Sm(m,mprior,icprior):\n",
    "    sm=((np.dot(0.5,(m-mprior).T))@icprior)@(m-mprior)\n",
    "    return sm\n",
    "# total misfit\n",
    "def S(m,dobs,mprior,icobs,icprior):\n",
    "    s=Sd(m,dobs,icobs) + Sm(m,mprior,icprior)\n",
    "    return s\n",
    "\n",
    "# initial model\n",
    "#mnew = mprior;     # prior model\n",
    "#mnew = mtarget;    # target model\n",
    "mnew = minitial;\n",
    "Sd_0 = Sd(mnew,dobs,icobs);\n",
    "Sm_0 = Sm(mnew,mprior,icprior);\n",
    "S_0  = S(mnew,dobs,mprior,icobs,icprior);\n",
    "stS0 = ' S(m0) = %.3f = %.3f(D) + %.3f(M)'% (S_0,Sd_0,Sm_0)\n",
    "print(stS0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 0\n",
    "#niter = input(' Select the number of iterations (< 10) or 0 to exit: ');\n",
    "#niter = int(niter)\n",
    "if int(niter) == 0:\n",
    "    sys.exit('no iterations requested: exiting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize arrays\n",
    "iter_vec = np.transpose(np.arange(0,niter+1))\n",
    "Sd_vec = np.zeros((niter+1,1));\n",
    "Sm_vec = np.zeros((niter+1,1));\n",
    "S_vec = np.zeros((niter+1,1));\n",
    "\n",
    "# misfit for initial model\n",
    "Sd_vec[0] = Sd_0;\n",
    "Sm_vec[0] = Sm_0;\n",
    "S_vec[0]  = S_0;\n",
    "\n",
    "for nn in range(1,niter+1):\n",
    "    #///////////////////////////////\n",
    "    # CODE HERE for quasi-Newton algorithm\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # misfit function for new model\n",
    "    # note: book-keeping only -- not used within the algorithm above\n",
    "    #Sd_vec[nn] = \n",
    "    #Sm_vec[nn] = \n",
    "    #S_vec[nn] = \n",
    "\n",
    "    #///////////////////////////////\n",
    "\n",
    "# misfit function values\n",
    "print('summary of misfit function:');\n",
    "print('%8s%16s%16s%16s'% ('iter','Sd','Sm','S = Sm + Sd'))\n",
    "for nn in range(niter):\n",
    "    print('%8i%16.10f%16.10f%16.10f' % (iter_vec[nn],Sd_vec[nn],Sm_vec[nn],S_vec[nn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ifig==1:\n",
    "    # plot convergence curve\n",
    "    ylims = [10**-2, 10**2];\n",
    "    stit = str(niter) +' iterations'\n",
    "    plt.plot(iter_vec, np.log10(Sd_vec),'r.-',iter_vec, np.log10(Sm_vec),'b.-',iter_vec, np.log10(S_vec),'k.-',\n",
    "        linewidth=2,markersize=20)\n",
    "    plt.legend(stlabS); plt.xlim([-0.5, niter+0.5]); plt.ylim(np.log10(ylims))\n",
    "    plt.locator_params(axis=\"x\", integer=True, tight=True)\n",
    "    plt.xlabel('k, iteration'); plt.ylabel(' log10[ S(m^k) ], misfit function'); plt.title(stit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrcov(cov):\n",
    "    # convert correlation matrix from covariance matrix\n",
    "    v = np.sqrt(np.diag(cov))\n",
    "    outer_v = np.outer(v, v)\n",
    "    corr = cov / outer_v\n",
    "    corr[cov == 0] = 0\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#///////////////////////////////\n",
    "# COMPUTE THE FOLLOWING\n",
    "# mpost       posterior model (\"final\" model)\n",
    "# dpost       predictions for mpost\n",
    "# Gpost       partial derivatives matrix at mpost\n",
    "# cpost0      posterior covariance matrix (use icobs0 and icprior0)\n",
    "# sigma_post  variances of the posterior covariance matrix\n",
    "# rho_post    posterior correlation matrix (hint: see Tarantola, Section 3.3)\n",
    "#\n",
    "# CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#///////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a priori model correlations (for comparison)\n",
    "rho_prior = corrcov(cprior0)\n",
    "print('cpost0 \\n', cpost0, '\\n', 'rho_post \\n', rho_post)\n",
    "\n",
    "# posterior data covariance matrix (e.g., Tarantola Eq. 3.44)\n",
    "cpost0_d = Gpost@cpost0@Gpost.T\n",
    "cpost0_d = (cpost0_d + cpost0_d.T)/2       # force to be symmetric\n",
    "sigma_post_d = np.sqrt(np.diag(cpost0_d))  # IGNORING OFF-DIAGONAL ELEMENTS\n",
    "rho_post_d = corrcov(cpost0_d)             # posterior correlation matrix\n",
    "rho_prior_d = corrcov(cobs0)               # prior, for comparison\n",
    "\n",
    "print('model summary (%i iterations):'% (niter))\n",
    "print('%16s%16s%16s%16s' % ('prior', 'initial','posterior', 'target'))\n",
    "for ii in range(nparm):\n",
    "        print('%16s%16s%16s%16s'%(str(mprior[ii]),str(minitial[ii]),str(mpost[ii]), str(mtarget[ii])))\n",
    "print('data summary (%i observations):' % (ndata))\n",
    "print('%16s%16s%16s%16s%16s'% ('prior', 'initial','posterior', 'target', 'actual'))\n",
    "for ii in range(ndata):\n",
    "        print('%16s%16s%16s%16s%16s'%(str(dprior[ii]),str(dinitial[ii]),str(dpost[ii]), \n",
    "                                      str(dtarget[ii]), str(dobs[ii])))\n",
    "# Cholesky decomposition to obtain the square-root of cpost0\n",
    "# NOTE: for large problems, this is not possible due to poor\n",
    "#       conditioning of cpost0 or the inability to compute cpost0\n",
    "Lpost = np.linalg.cholesky(cpost0);\n",
    "\n",
    "# samples of the posterior distribution\n",
    "mpost_samples = np.zeros((nparm,nsamples))\n",
    "mcov_samples = np.zeros((nparm,nsamples))\n",
    "for xx in range(nsamples): \n",
    "    randn_vecs_m[:,xx] = np.random.randn(nparm)\n",
    "mcov_samples  = Lpost @ randn_vecs_m;\n",
    "mpost_samples = np.matlib.repmat(mpost,1,nsamples) + mcov_samples;\n",
    "\n",
    "# compare the standard deviation with sigma_post\n",
    "\n",
    "std_samples = np.std(mpost_samples.T, axis=0);\n",
    "\n",
    "# compare posterior model distribution with prior\n",
    "# note: format statement allows for vectors (like sigma_prior)\n",
    "print('  ');\n",
    "print(' Compare model uncertainties : ');\n",
    "print('             model parameter : %13s%13s%13s%13s' %(mlabs[0],mlabs[1],mlabs[2],mlabs[3]))\n",
    "print('                       units : %13s%13s%13s%13s' %(ulabs[0],ulabs[1],ulabs[2],ulabs[3]));\n",
    "print('                 sigma_prior = %13.5s%13.5s%13.5s%13.5s'%(sigma_prior[0],sigma_prior[1],\n",
    "                                                                 sigma_prior[2],sigma_prior[3]))\n",
    "print('                  sigma_post = %13.5s%13.5s%13.5s%13.5s'%(sigma_post[0],sigma_post[1],\n",
    "                                                                 sigma_post[2],sigma_post[3]));\n",
    "print('   std(%6.0f mpost_samples) = %13.5s%13.5s%13.5s%13.5s' % (nsamples, std_samples[0],std_samples[1],\n",
    "                                                                  std_samples[2],std_samples[3]));\n",
    "print('    sigma_post / sigma_prior = %13.5s%13.5s%13.5s%13.5s' % (np.divide(sigma_post[0],sigma_prior[0]),\n",
    "                                                                  np.divide(sigma_post[1],sigma_prior[1]),\n",
    "                                                                  np.divide(sigma_post[2],sigma_prior[2]),\n",
    "                                                                  np.divide(sigma_post[3],sigma_prior[3])));\n",
    "print('1 - sigma_post / sigma_prior = %13.5s%13.5s%13.5s%13.5s' % (1 - np.divide(sigma_post[0],sigma_prior[0]),\n",
    "                                                                  1 - np.divide(sigma_post[1],sigma_prior[1]),\n",
    "                                                                  1 - np.divide(sigma_post[2],sigma_prior[2]),\n",
    "                                                                  1 - np.divide(sigma_post[3],sigma_prior[3])))\n",
    "print('  ')              \n",
    "\n",
    "# compute the predictions associated with the posterior samples,\n",
    "# then compare std_d_samples with sigma_post_d\n",
    "d_samples = np.zeros((ndata,nsamples))\n",
    "for xx in range(nsamples):\n",
    "    ms = mpost_samples[:,xx]\n",
    "    d_samples[:,xx] = d(ms)\n",
    "\n",
    "covd_samples = np.cov(d_samples)\n",
    "rhod_samples = corrcov(covd_samples)\n",
    "std_d_samples = np.sqrt(np.diag(covd_samples))\n",
    "#std_d_samples = std(d_samples');\n",
    "\n",
    "print('  ');\n",
    "print(' Compare data uncertainties : ')\n",
    "print('%16s %10s %10s %10s'%('prior','post','samples','post/prior'))\n",
    "call = [sigma_obs, sigma_post_d, std_d_samples, np.divide(sigma_post_d,sigma_obs)];\n",
    "for ii in range(ndata):\n",
    "    print('%6i%10.4f %10.4f %10.4f %10.4f'%(ii+1,call[0][ii],call[1][ii],call[2][ii],call[3][ii]))\n",
    "print('  ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covsamples(msamples,rho,tlab,sym1,msamples2,rho2,tlab2,sym2,mlabs):\n",
    "    # generates plots for samples of covariance matrix\n",
    "    #\n",
    "    # INPUT\n",
    "    #    msamples   n x p matrix of vector samples\n",
    "    #    rho        n x n 'analytical' correlation matrix\n",
    "    #    tlab       label for plot\n",
    "    #    sym1       plotting symbol\n",
    "    #    msamples2  optional: 2nd set of samples ([] for none)\n",
    "    #    rho2       optional: 2nd 'analytical' correlation matrix ([] for none)\n",
    "    #    tlab2      optional: label for plot\n",
    "    #    sym2       optional: plotting symbol\n",
    "    #    mlabs      optional: labels for each variable ([] for default)\n",
    "    #\n",
    "    # EXAMPLE: \n",
    "    #    plot_covsamples(mpost_samples,rho_post,'mpost','b.',[],[],[],[],mlabs);\n",
    "    #\n",
    "    # NOTE: We could alternatively estimate the covariance matrix\n",
    "    # (and correlation matrix) directly from the input samples.\n",
    "    #\n",
    "    # Carl Tape, 2012-01-01\n",
    "\n",
    "    NMAX = 6;   # max number to make into scatterplot\n",
    "    \n",
    "    n = np.shape(msamples)[0]\n",
    "    p = np.shape(msamples)[1]\n",
    "    print('plot_covsamples: n = %i, p = %i'%(n,p))\n",
    "    \n",
    "    if len(mlabs)==0:\n",
    "        #mlabs = strtrim(cellstr(num2str([1:n]')));\n",
    "        mlabs = []#np.matlib.repmat(str(''),n,1);\n",
    "        for ii in range(n):\n",
    "            mlabs.append( 'i'+str(ii+1))        \n",
    "    # whether to plot a second set of samples\n",
    "    if len(msamples2)!=0 and len(rho2)!=0:\n",
    "        isecond = 1; \n",
    "    else:\n",
    "        isecond = 0\n",
    "    \n",
    "    # kk=1: correlation matrices from Cpost\n",
    "    # kk=2: correlation matrices based on input SAMPLES\n",
    "    fig=plt.figure(figsize=(8,8));\n",
    "    \n",
    "    nr=1+isecond; nc=2;\n",
    "    for kk in [0,1]:\n",
    "        if kk==0:\n",
    "            F1 = rho; \n",
    "            if isecond==1:\n",
    "                F2 = rho2\n",
    "            stag = ''\n",
    "        else:\n",
    "            F1 = np.corrcoef(msamples);\n",
    "            if isecond==2:\n",
    "                F2 = np.corrcoef(msamples2)\n",
    "            stag = 'sample'\n",
    "        \n",
    "        # first matrix plot\n",
    "        pind = kk+1+isecond*(kk);\n",
    "        ax = fig.add_subplot(nr,nc,pind)\n",
    "        p1=ax.imshow(F1,cmap='jet', vmin=-1,vmax=1);\n",
    "        ax.xaxis.tick_top()\n",
    "        if isecond==0:\n",
    "            fig.colorbar(p1,shrink=0.3, aspect=10,ticks=[-1, -0.5, 0, 0.5, 1])\n",
    "        else:\n",
    "            fig.colorbar(p1,shrink=0.7, aspect=10,ticks=[-1, -0.5, 0, 0.5, 1])\n",
    "        if len(mlabs)==4:\n",
    "            plt.xticks([0,1,2,3],mlabs)\n",
    "            plt.yticks([0,1,2,3],mlabs)\n",
    "        else:\n",
    "            plt.xticks(np.arange(0,n,1),mlabs)\n",
    "            plt.yticks(np.arange(0,n,1),mlabs)\n",
    "        plt.title(str(stag)+ ' correlation matrix for '+ str(tlab));\n",
    "        \n",
    "        # second matrix plot (OPTIONAL)\n",
    "        if isecond==1:\n",
    "            ax2 = fig.add_subplot(nr,nc,pind+1)\n",
    "            p2=ax2.imshow(F2, cmap='jet', vmin=-1,vmax=1); #caxis([-1 1]), colorbar\n",
    "            ax2.xaxis.tick_top()\n",
    "            if len(mlabs)==4:\n",
    "                plt.xticks([0,1,2,3],mlabs)\n",
    "                plt.yticks([0,1,2,3],mlabs)\n",
    "            else:\n",
    "                plt.xticks(np.arange(0,n,1),mlabs)\n",
    "                plt.yticks(np.arange(0,n,1),mlabs)\n",
    "            plt.title(str(stag)+ ' correlation matrix for '+ str(tlab2));\n",
    "            fig.colorbar(p2,shrink=0.7, aspect=10,ticks=[-1, -0.5, 0, 0.5, 1])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # scatterplots\n",
    "    if n > NMAX:\n",
    "        print('n = %i is > %i, so no scatterplots made'% (n,NMAX))\n",
    "    else:\n",
    "        fig=plt.figure(figsize=(8,8)); \n",
    "        nr=n-1; nc=n-1;\n",
    "        for ii in range(n-1):\n",
    "            jj=ii+1\n",
    "            while jj<n: \n",
    "                px = np.array([msamples[ii,:]])\n",
    "                py = np.array([msamples[jj,:]])\n",
    "                iplot = nc*(ii) + jj;\n",
    "                #disp([ii jj iplot]);\n",
    "                ax = fig.add_subplot(nr,nc,iplot)\n",
    "                ax.plot(px,py,sym1,markersize=2);\n",
    "                ax.xaxis.tick_bottom()\n",
    "                plt.xlabel(mlabs[ii]); plt.ylabel(mlabs[jj]);\n",
    "                st1 = 'corr(%s) = %.2f (%.2f)'% (tlab,np.corrcoef(px,py,ddof=0)[0,1],rho[ii,jj]);\n",
    "                if isecond==1:\n",
    "                    px = msamples2[ii,:]\n",
    "                    py = msamples2[jj,:]\n",
    "                    plt.plot(px,py,sym2,markersize=2);\n",
    "                    st2 = 'corr(%s) = %.2f (%.2f)'% (tlab2,np.corrcoef(px,py,ddof=0)[0,1],rho2[ii,jj])\n",
    "                    plt.title(str(st1)+'\\n'+ str(st2));\n",
    "                else:\n",
    "                    plt.title(str(st1));\n",
    "                jj+=1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ifig==1:\n",
    "    # display distributions for each model parameter (nparm ROWS of cov_samples_m)\n",
    "    fig=plt.figure(figsize=(8,8));\n",
    "    nr=2; nc=2;\n",
    "    for kk in range(nparm):\n",
    "        sigma = sigma_post[kk];\n",
    "        edges=np.arange(-4*sigma,4*sigma,sigma/2)\n",
    "        etemp = mcov_samples[kk,:]\n",
    "        plt.subplot(nr,nc,kk+1); \n",
    "        plot_histo(etemp,edges); \n",
    "        plt.ylim([0, 0.4]); \n",
    "        plt.grid\n",
    "        stl1 = 'mpost samples'\n",
    "        stl2 = 'Model parameter ' +str(kk+1) +' (' +str(mlabs[kk]) +')'\n",
    "        stl3 = 'mean = %.5f; std = %.5f' % (np.mean(etemp),np.std(etemp))\n",
    "\n",
    "        if kk==0: \n",
    "            plt.title(str(stl1) + ': ' + str(stl2) + '\\n'+str(stl3))\n",
    "        else: \n",
    "            plt.title(str(stl2) + '\\n'+str(stl3))\n",
    "    plt.tight_layout()\n",
    "    # correlation matrices and scatterplots\n",
    "    #plot_covsamples(mprior_samples,rho_prior,'mprior','b.',[],[],[],[],mlabs);\n",
    "    plot_covsamples(mpost_samples,rho_post,'mpost','r.',[],[],[],[],mlabs);\n",
    "    plot_covsamples(mprior_samples,rho_prior,'mprior','b.',mpost_samples,rho_post,'mpost','r.',mlabs);\n",
    "\n",
    "    # 'physical view' of estimated posterior data uncertainties\n",
    "    # note: plot either sigma_post_d (from Cpost_d) or std_d_samples (from d(Cpost_samples))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(aspect=1)\n",
    "    plt.plot(mpost_samples[0,:],mpost_samples[1,:],'c.');\n",
    "    plt.plot(mpost[0],mpost[1],'o',markersize=10,markerfacecolor='c',markeredgecolor='w');\n",
    "    #plot(mprior(1),mprior(2),'o','markersize',10,'markerfacecolor','b','markeredgecolor','w');\n",
    "    #scatter(xrec,yrec,16^2,sigma_post_d,'filled','V'); title('estimated uncertainties for posterior predictions');\n",
    "\n",
    "    plt.scatter(xrec,yrec,16**2,std_d_samples,marker='v',edgecolors='k', cmap='hot'); \n",
    "    #plt.scatter(xrec,yrec,16**2,'k',marker='v', cmap='hot');\n",
    "    plt.xlim([0,100]);plt.ylim([0,100])\n",
    "    #set(gca,'xtick',[0:20:100],'ytick',[0:20:100]);\n",
    "    plt.xlabel('X distance (km)'); plt.ylabel('Y distance (km)');\n",
    "    plt.colorbar(shrink=0.8);\n",
    "    plt.title('uncertainties for posterior predictions, computed from samples');\n",
    "    plt.show()\n",
    "    # plot predictions for samples of the posterior\n",
    "    plot_covsamples(d_samples,rho_post_d,'dpost','k.',[],[],[],[],[]);\n",
    "\n",
    "    #plt.subplot(aspect=1)\n",
    "    # note: opts is set in forward_epicenter\n",
    "    plot_epicenters(mprior_samples,mprior,minitial,mtarget,opts,mpost);\n",
    "    # plot the cpost0 samples and re-plot the two markers\n",
    "    plt.plot(mpost_samples[0,:],mpost_samples[1,:],'c.')\n",
    "    plt.plot(mpost[0],mpost[1],'o',markersize=10,markerfacecolor='c',markeredgecolor='w')\n",
    "    plt.plot(mtarget[0],mtarget[1],'o',markersize=10,markerfacecolor='r',markeredgecolor='w')\n",
    "    plt.plot(minitial[0],minitial[1],'o',markersize=10,markerfacecolor='k',markeredgecolor='w')\n",
    "    #plt.xlim([0,100]);plt.ylim([0,100]);plt.axis('equal')\n",
    "    plt.title('samples of prior (blue) and posterior (cyan)');\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
